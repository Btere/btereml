{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oQPyoN-77RQTUpyA3tD2R4kvQ5fiUIx3",
      "authorship_tag": "ABX9TyPwINzW6EgvGGw3+ClsrqpR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Btere/btereml/blob/main/creditcard_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "XATPfMARQxM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = Path(\"/content/drive/MyDrive/Colab Notebooks\")"
      ],
      "metadata": {
        "id": "wcehiOAKQxQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv_files(dataset_path: Path)-> pd.DataFrame:\n",
        "    train_dataset = pd.read_csv(f'{dataset_path}/fraudTrain.csv', index_col=False)\n",
        "    test_dataset = pd.read_csv(f'{dataset_path}/fraudTest.csv', index_col=False)\n",
        "    return train_dataset, test_dataset"
      ],
      "metadata": {
        "id": "ALNpjxULQxTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = read_csv_files(DATASET_PATH)\n"
      ],
      "metadata": {
        "id": "dWR7GWaMQxWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(train_dataset)"
      ],
      "metadata": {
        "id": "utuP-JAZSHQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset overview\n",
        "\n",
        "train_dataset.shape"
      ],
      "metadata": {
        "id": "XZXq9VDkVhpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.shape"
      ],
      "metadata": {
        "id": "-61cqdY2VhnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.columns"
      ],
      "metadata": {
        "id": "y0l1zujCWAGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.info()"
      ],
      "metadata": {
        "id": "nm8FBQ-lV1nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "EkkdPJGLWGdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.isna().sum()"
      ],
      "metadata": {
        "id": "yu_cZhIcWGLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(test_dataset)"
      ],
      "metadata": {
        "id": "z9cuVGjISHUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.nunique()"
      ],
      "metadata": {
        "id": "0D_tU-B2SHXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[\"is_fraud\"].value_counts()"
      ],
      "metadata": {
        "id": "J9RUbLd-SGFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[\"is_fraud\"].value_counts()"
      ],
      "metadata": {
        "id": "PBmIGu2eSGId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning"
      ],
      "metadata": {
        "id": "3Rk8Xdu4cizL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_dataset.drop(columns='Unnamed: 0')\n",
        "test_data = test_dataset.drop(columns='Unnamed: 0')"
      ],
      "metadata": {
        "id": "cS-BWgyLYJw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"dob\"] = pd.to_datetime(train_data[\"dob\"])\n",
        "train_data['trans_date_trans_time'] = pd.to_datetime(train_data['trans_date_trans_time'])"
      ],
      "metadata": {
        "id": "s96EC69dSBSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "_5eBD9XvSBVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[\"dob\"] = pd.to_datetime(test_data[\"dob\"])\n",
        "test_data['trans_date_trans_time'] = pd.to_datetime(test_data['trans_date_trans_time'])"
      ],
      "metadata": {
        "id": "4rzldSV2fsbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "EG3rqOg7SBXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.describe()"
      ],
      "metadata": {
        "id": "rULmKg7ZQxYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape , test_data.shape"
      ],
      "metadata": {
        "id": "aVUyeSM-di_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns , test_data.columns"
      ],
      "metadata": {
        "id": "EVkvXOoIdjB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we want to apply some transformation to the dataset to normalize the features values before encoding the categorical labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "uS6qugSGfBw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "counts the number of occurrences of each job title among the rows in the test_data DataFrame where the is_fraud column is 1. It helps in understanding the distribution of job titles specifically for fraudulent cases in the dataset."
      ],
      "metadata": {
        "id": "CFqXZG8ApEMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[test_data[\"is_fraud\"] == 1][\"job\"].value_counts()"
      ],
      "metadata": {
        "id": "HCR5Dg0Yod0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[train_data[\"is_fraud\"] == 1][\"merchant\"].value_counts()"
      ],
      "metadata": {
        "id": "XNaCZTqAoOfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding test data\n",
        "encoder=LabelEncoder()\n",
        "\n",
        "test_data['merchant']=encoder.fit_transform(test_data['merchant'])\n",
        "test_data['category']=encoder.fit_transform(test_data['category'])\n",
        "test_data['street']=encoder.fit_transform(test_data['street'])\n",
        "test_data['job']=encoder.fit_transform(test_data['job'])\n",
        "test_data['trans_num']=encoder.fit_transform(test_data['trans_num'])\n",
        "test_data['first']=encoder.fit_transform(test_data['first'])\n",
        "test_data['city']=encoder.fit_transform(test_data['city'])\n",
        "test_data['state']=encoder.fit_transform(test_data['state'])\n",
        "test_data['last']=encoder.fit_transform(test_data['last'])\n",
        "test_data['gender']=encoder.fit_transform(test_data['gender'])\n",
        "test_data['trans_date_trans_time']=encoder.fit_transform(test_data['trans_date_trans_time'])\n",
        "test_data['dob']=encoder.fit_transform(test_data['dob'])"
      ],
      "metadata": {
        "id": "QNiYbEscgd7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "kZl9H5GZgk_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "\n",
        "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    standard_scaler = StandardScaler()\n",
        "    minmax_scaler = MinMaxScaler()\n",
        "\n",
        "    # Separate numerical and categorical columns\n",
        "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Scale and Normalize numerical columns\n",
        "    if len(numerical_cols) > 0:\n",
        "        # First, apply MinMaxScaler for normalization\n",
        "        df[numerical_cols] = minmax_scaler.fit_transform(df[numerical_cols])\n",
        "        # Then, apply StandardScaler for scaling\n",
        "        df[numerical_cols] = standard_scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "    # Encode categorical columns\n",
        "    for column in categorical_cols:\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "0emKL0aFdjEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = preprocess_data(train_data)\n",
        "display(train_df)"
      ],
      "metadata": {
        "id": "pkZ84FUAdjI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "YWDJxbdtgIGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.describe()"
      ],
      "metadata": {
        "id": "CrblarlagIRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "p_82CZ9LdjLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_data.copy()"
      ],
      "metadata": {
        "id": "PWUex-BkdjMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_data.copy()"
      ],
      "metadata": {
        "id": "hOpqwjhijo3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting dataset and convert to a numpy array.\n",
        "X_train = train_df.loc[:, train_df.columns != 'is_fraud'].values\n",
        "y_train = train_df.loc[:, 'is_fraud'].values\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "cLA-J85ojo7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_df.loc[:, test_df.columns != 'is_fraud'].values\n",
        "y_test = test_df.loc[:, 'is_fraud'].values\n",
        "\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "FLreBF6yjpEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model building and training\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score , classification_report , confusion_matrix\n",
        "\n",
        "modelLR = LogisticRegression(random_state = 42,n_estimators = 10, n_jobs = -1, max_depth = 20)\n",
        "modelRF = RandomForestClassifier(random_state = 42,n_estimators = 10, n_jobs = -1, max_depth = 20)\n",
        "modelDT = DecisionTreeClassifier()\n",
        "\n"
      ],
      "metadata": {
        "id": "fKKVeP3-rIHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In NumPy, the reshape function is used to change the shape of an array without changing its data. The arguments (-1, 1) and (1, -1) specify how the array should be reshaped. Here’s a detailed explanation of each:\n",
        "\n",
        "reshape(-1, 1)\n",
        "-1: This is a special placeholder used in NumPy’s reshape method. It tells NumPy to automatically determine the size of this dimension based on the size of the array and the remaining dimensions.\n",
        "1: This specifies that the resulting shape should have a single column.\n",
        "\n",
        "\n",
        "Explanation: The -1 tells NumPy to infer the number of rows based on the total number of elements (which is 6 in this case) and the specified number of columns (1). So, the resulting shape is (6, 1).\n",
        "\n",
        "reshape(1, -1)\n",
        "1: This specifies that the resulting shape should have a single row.\n",
        "-1: This tells NumPy to automatically determine the size of this dimension based on the size of the array and the remaining dimensions.\n",
        "\n",
        "\n",
        "Explanation: The -1 tells NumPy to infer the number of columns based on the total number of elements (which is 6 in this case) and the specified number of rows (1). So, the resulting shape is (1, 6).\n",
        "\n",
        "Summary\n",
        "reshape(-1, 1) converts a 1D array into a 2D array with one column and as many rows as needed.\n",
        "reshape(1, -1) converts a 1D array into a 2D array with one row and as many columns as needed.\n",
        "The -1 in the reshape function is useful for automatically calculating dimensions when you only need to specify one of the dimensions, making it easier to reshape arrays without manually calculating the required sizes."
      ],
      "metadata": {
        "id": "Ef1Blt6tnl3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# Reshape to a 2D array with 1 column\n",
        "reshaped_arr = arr.reshape(-1, 1)\n",
        "print(reshaped_arr)"
      ],
      "metadata": {
        "id": "ZYb_lLYnndl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_arr = arr.reshape(1, -1)\n",
        "print(reshaped_arr)"
      ],
      "metadata": {
        "id": "PtQVT6HMndpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFORY916ndyK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}